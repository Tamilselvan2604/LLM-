{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64c430b9-5b8f-4474-858f-5b2f7a03e054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\mm\\lib\\site-packages (from evaluate) (2.19.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\mm\\lib\\site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in c:\\mm\\lib\\site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\mm\\lib\\site-packages (from evaluate) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\mm\\lib\\site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\mm\\lib\\site-packages (from evaluate) (4.65.0)\n",
      "Requirement already satisfied: xxhash in c:\\mm\\lib\\site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\mm\\lib\\site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in c:\\mm\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\mm\\lib\\site-packages (from evaluate) (0.27.1)\n",
      "Requirement already satisfied: packaging in c:\\mm\\lib\\site-packages (from evaluate) (23.1)\n",
      "Requirement already satisfied: filelock in c:\\mm\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\mm\\lib\\site-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\mm\\lib\\site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in c:\\mm\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\mm\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\mm\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\mm\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\mm\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\mm\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\mm\\lib\\site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\mm\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\mm\\lib\\site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\mm\\lib\\site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\mm\\lib\\site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\mm\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\mm\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\mm\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\mm\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\mm\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\mm\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Installing collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f7b12ce-0bd9-4a4d-b056-19f82fc1e0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 247577856\n",
      "all model parameters: 247577856\n",
      "percentage of trainable model parameters: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# Set device to GPU if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open(r'C:\\Users\\Tamilselvan M\\Downloads\\ML\\FILE\\risk_assement.json', 'r') as file:\n",
    "    dataset = json.load(file)\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"google/flan-t5-base\"\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return (f\"trainable model parameters: {trainable_model_params}\\n\"\n",
    "            f\"all model parameters: {all_model_params}\\n\"\n",
    "            f\"percentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\")\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(base_model))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2801a39-3673-43bf-b030-189ed9558c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter disaster details (e.g., Disaster_Type: Tornado, Location: China, Magnitude: 2.7, Fatalities: 3534, Economic_Loss($): 574465547.8):  earthquake,india,2.7,9000,568299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Prompt: earthquake,india,2.7,9000,568299\n",
      "--------------------------------------------------------------------\n",
      "Expected output:\n",
      "Moderate-risk disaster. Consider evacuation planning and resource allocation.\n",
      "---------------------------------------------------------------------\n",
      "Model generated summary:\n",
      "The earthquake in India has a magnitude of 2.7,9000,568299.\n"
     ]
    }
   ],
   "source": [
    "user_input = input(\"Enter disaster details (e.g., Disaster_Type: Tornado, Location: China, Magnitude: 2.7, Fatalities: 3534, Economic_Loss($): 574465547.8): \")\n",
    "\n",
    "# Create prompt for summarization\n",
    "prompt = f\"Summarize the following risk assessment dialogue: {user_input} Summary:\"\n",
    "\n",
    "# Tokenize input and generate summary\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "output_ids = base_model.generate(input_ids, max_new_tokens=200)\n",
    "output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Print results\n",
    "print(f\"Input Prompt: {user_input}\")\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "print(\"Expected output:\")\n",
    "print(\"Moderate-risk disaster. Consider evacuation planning and resource allocation.\")  # Example expected output\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "print(\"Model generated summary:\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35cd879-86c4-4bbd-a008-30ec15a04cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
